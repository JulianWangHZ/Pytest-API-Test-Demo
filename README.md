# FakeStore API Automation Testing Framework

A professional, comprehensive API automation testing architecture specifically designed for testing the [FakeStore API](https://fakestoreapi.com/docs).

## ğŸ“‹ Project Overview

This is a Python-based API testing framework that uses pytest as the test runner and integrates with the Allure reporting system. The framework supports multi-environment configuration, data-driven testing, parameterized testing, and provides a complete CI/CD integration solution.

![Test Results Demo](assets/test_results.gif)

[ğŸ”— View Latest Test Report](https://julianwanghz.github.io/Pytest-API-Test-Demo/allure-report/)

## ğŸ“‹ Key Features

- **Modular Design**: Clear architectural separation for easy maintenance and scalability
- **Data-Driven Testing**: Support for JSON format test data
- **Allure Reporting**: Beautiful test reports with detailed test steps
- **Environment Management**: Multi-environment configuration support (staging/production)
- **Robust Validation**: Multi-layer response validation (status codes, response time, JSON Schema)
- **Complete HTTP Support**: GET, POST, PUT, PATCH, DELETE methods
- **Auto Retry Mechanism**: Intelligent retry for network errors
- **Parallel Execution**: Support for pytest-xdist parallel testing
- **Docker Support**: Containerized testing environment for consistency

## ğŸ—ï¸ Project Architecture

```
pytest-api-demo/
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py        # Configuration loader
â”‚   â”œâ”€â”€ environments.json       # Environment configurations
â”‚   â”œâ”€â”€ test_settings.json      # Test settings
â”‚   â””â”€â”€ endpoints.json          # API endpoint configurations
â”œâ”€â”€ utils/                      # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api_client.py          # HTTP client
â”‚   â”œâ”€â”€ validators.py          # Response validators
â”‚   â”œâ”€â”€ helpers.py             # Test helper utilities
â”‚   â””â”€â”€ data_provider.py       # Test data provider
â”œâ”€â”€ tests/                      # Test cases
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_products.py       # Products API tests
â”‚   â”œâ”€â”€ test_users.py          # Users API tests
â”‚   â”œâ”€â”€ test_carts.py          # Carts API tests
â”‚   â””â”€â”€ test_auth.py           # Authentication API tests
â”œâ”€â”€ test_data/                  # Test data
â”‚   â”œâ”€â”€ products_test_data.json
â”‚   â”œâ”€â”€ users_test_data.json
â”‚   â”œâ”€â”€ carts_test_data.json
â”‚   â””â”€â”€ schemas/               # JSON Schemas
â”‚       â”œâ”€â”€ product_schema.json
â”‚       â”œâ”€â”€ user_schema.json
â”‚       â””â”€â”€ cart_schema.json
â”œâ”€â”€ reports/                    # Test reports
â”‚   â”œâ”€â”€ allure/
â”‚   â”œâ”€â”€ html/
â”‚   â”œâ”€â”€ coverage/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ conftest.py                # pytest global configuration
â”œâ”€â”€ pytest.ini                # pytest settings
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                  # Project documentation
```

## ğŸš€ Quick Start Guide

### 1. Clone Repository

```bash
git clone <your-repo-url>
cd pytest-api-demo
```

### 2. Choose Execution Method

#### Option A: Docker (Recommended)

```bash
# One-click test execution
make docker-test

# View test reports
ls -la reports/
```

#### Option B: Local Development

```bash
# Install dependencies (requires virtual environment on macOS)
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run tests
pytest -m smoke
```

## ğŸ³ Docker Usage (Recommended)

### Why Use Docker?

- âœ… **Environment Consistency**: Ensures all developers use the same testing environment
- âœ… **No Local Dependencies**: No need to install Python dependencies locally
- âœ… **Quick Deployment**: One-click build and run
- âœ… **Isolated Environment**: Won't pollute your local development environment

### Build Docker Image

```bash
# Build Docker image
docker build -t fakestore-api-tests .

# Or use Makefile (simpler)
make docker-build
```

### Running Tests

#### 1. Using Makefile (Recommended)

```bash
# Build and run all tests
make docker-test

# Build image only
make docker-build
```

#### 2. Using Docker Commands

```bash
# Run all tests
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests

# Run smoke tests
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest -m smoke -v

# Run specific test file
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest tests/test_products.py -v

# Run specific test case
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest tests/test_products.py::TestGetProducts::test_get_all_products -v

# Run tests with specific markers
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest -m "products and positive" -v
```

### Common Test Commands

```bash
# 1. Quick Smoke Tests (Basic functionality verification)
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest -m smoke -v

# 2. Complete Product API Tests
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest tests/test_products.py -v

# 3. Positive Test Cases
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest -m positive -v

# 4. Negative Test Cases
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest -m negative -v

# 5. Specific Test Method
docker run --rm -v $(pwd)/reports:/app/reports fakestore-api-tests pytest tests/test_products.py::TestGetProducts::test_get_product_invalid_id -v
```

### Viewing Reports

After test completion, reports are automatically saved to the `./reports` directory:

```bash
# View generated reports
ls -la reports/

# Reports directory structure
reports/
â”œâ”€â”€ allure/          # Allure test reports
â”œâ”€â”€ html/            # HTML test reports
â”œâ”€â”€ coverage/        # Code coverage reports
â””â”€â”€ logs/            # Test logs
```

### Docker Environment Variables

```bash
# Specify test environment
docker run --rm \
  -e ENVIRONMENT=staging \
  -v $(pwd)/reports:/app/reports \
  fakestore-api-tests pytest -m smoke -v

# Specify base URL
docker run --rm \
  -e BASE_URL=https://fakestoreapi.com \
  -v $(pwd)/reports:/app/reports \
  fakestore-api-tests
```

## ğŸ› ï¸ Environment Setup Options

### Option 1: Docker (Recommended)

- **Use Cases**: Production environment, CI/CD, team collaboration
- **Benefits**: Environment consistency, quick deployment, no dependency conflicts
- **Commands**: `make docker-test` or `docker run ...`

### Option 2: Local Development

- **Use Cases**: Development debugging, IDE integration, quick testing
- **Prerequisites**: Need to install dependencies first `pip install -r requirements.txt`
- **Commands**: `pytest -m smoke`

### â— Important Notes

**Docker and Local are Independent Environments**:

- Docker installs dependencies **inside the container** during build
- Local environment needs to **separately install** dependencies to run pytest
- Docker is recommended for environment consistency

## ğŸ§‘ğŸ»â€ğŸ¤ Test Types

### Pytest Markers

- `@pytest.mark.smoke`: Smoke tests
- `@pytest.mark.regression`: Regression tests
- `@pytest.mark.positive`: Positive test cases
- `@pytest.mark.negative`: Negative test cases
- `@pytest.mark.boundary`: Boundary value tests
- `@pytest.mark.products`: Products API related
- `@pytest.mark.users`: Users API related
- `@pytest.mark.carts`: Carts API related
- `@pytest.mark.auth`: Authentication API related

### Run Specific Test Types

```bash
# Run smoke tests
pytest -m smoke -v

# Run positive test cases
pytest -m positive -v

# Run product and user related tests
pytest -m "products or users" -v

# Exclude specific tests
pytest -m "not slow" -v
```

## ğŸ“Š Test Reports

### Allure Reports

```bash
# Generate and serve Allure report
pytest --alluredir=reports/allure/results
allure serve reports/allure/results
```

### HTML Reports

```bash
# Generate HTML report
pytest --html=reports/html/report.html --self-contained-html
```

### Coverage Reports

```bash
# Generate coverage report
pytest --cov=utils --cov=config --cov-report=html:reports/coverage
```

## ğŸ”§ API Client Usage

```python
from utils import APIClient

# Initialize client
client = APIClient()

# Products API
response = client.products.get_all()
response = client.products.get_by_id(1)
response = client.products.create(product_data)

# Users API
response = client.users.get_all()
response = client.users.create(user_data)

# Carts API
response = client.carts.get_all()
response = client.carts.get_user_carts(1)

# Authentication API
response = client.auth.login(credentials)
```

## ğŸ“ Test Data Management

### Loading Test Data

```python
from utils import DataProvider

data_provider = DataProvider()

# Load product test data
product_data = data_provider.get_positive_test_data("products")

# Generate random test data
random_product = data_provider.get_random_test_data("products", count=1)

# Get invalid data variations
invalid_data = data_provider.get_invalid_data_variations("products")
```

### Custom Test Data

Create JSON files in the `test_data/` directory:

```json
{
  "test_cases": [
    {
      "test_type": "positive",
      "name": "valid_data",
      "data": {...},
      "expected_fields": ["id", "name"]
    }
  ]
}
```

## ğŸ” Response Validation

```python
from utils import ResponseValidator

validator = ResponseValidator()

# Basic validation
assert validator.validate_status_code(response, 200)
assert validator.validate_content_type(response, "application/json")
assert validator.validate_response_time(response, max_time=5.0)

# Field validation
assert validator.validate_required_fields(response, ["id", "title", "price"])

# JSON Schema validation
assert validator.validate_json_schema(response, "product_schema")
```

## ğŸ› ï¸ Development Tools

### Code Formatting

```bash
black .
```

### Static Analysis

```bash
flake8
mypy .
```

### Pre-commit Hooks

```bash
pre-commit install
pre-commit run --all-files
```

## ğŸ“ˆ Continuous Integration

This framework supports integration with CI/CD tools:

```bash
# Jenkins/GitHub Actions
pytest -m "smoke" --alluredir=allure-results
```

## ğŸ¯ Using Makefile Commands

This project includes a Makefile for convenient command execution:

```bash
# Show all available commands
make help

# Quick setup and install
make install

# Run different test types
make smoke          # Run smoke tests
make regression     # Run regression tests
make products       # Run product API tests
make parallel       # Run tests in parallel

# Generate reports
make allure         # Generate and serve Allure report
make html-report    # Generate HTML report
make coverage       # Generate coverage report

# Development tasks
make format         # Format code with black
make lint           # Run linting checks
make clean          # Clean generated files

# Combined tasks
make quick-check    # Format + lint + smoke tests
make full-check     # Format + lint + all tests + coverage
```

## ğŸ“š Additional Resources

- [FakeStore API Documentation](https://fakestoreapi.com/docs)
- [Pytest Official Documentation](https://docs.pytest.org/)
- [Allure Report Documentation](https://docs.qameta.io/allure/)
- [Requests Documentation](https://requests.readthedocs.io/)

## ğŸ“‹ Project Status

This is a complete, production-ready API testing framework that includes:

âœ… **Core Components**

- Configuration management with JSON
- HTTP client with retry mechanisms
- Response validators with multi-layer validation
- Test data providers with data-driven support
- Test helpers for common operations

âœ… **Test Infrastructure**

- Comprehensive pytest configuration
- Allure reporting integration
- Parallel test execution support
- Custom markers and fixtures
- Environment management

âœ… **Documentation & Tools**

- Complete README with usage examples
- Makefile for common operations
- Proper project structure
- JSON schemas for validation

âœ… **Ready for Extension**

- Easy to add new API endpoints
- Scalable test data management
- Modular design for maintainability
- CI/CD integration ready

## ğŸ“Š Test Markers and Usage

```bash
# Test type markers
pytest -m smoke      # Smoke tests (basic functionality verification)
pytest -m regression # Regression tests
pytest -m positive   # Positive test cases
pytest -m negative   # Negative test cases

# API functionality markers
pytest -m products   # Product-related APIs
pytest -m users      # User-related APIs
pytest -m carts      # Cart-related APIs
pytest -m auth       # Authentication-related APIs
```
